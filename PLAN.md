# Project Plans Overview

This document provides a consolidated overview of all planning documents, ordered chronologically by their sequential numbering.

| Plan File Name | General Planning Description | Implementations Completed |
|---|---|---|
| PLAN_001_REFACTOR_HTTP_CLIENTS.md | Refactoring Plan: HTTPClient and RequestsManager | - Dependency Analysis: Identify all files and functions that import and use the HTTPClient and RequestsManager classes. - Refactor HTTPClient (fbpyutils_ai/tools/http.py): Remove JSON parsing logic and return the raw httpx.Response object directly. - Refactor RequestsManager (fbpyutils_ai/tools/http.py): Remove JSON parsing logic and return the raw requests.Response object directly. - Update Client Code: Modify the code to receive raw response objects and add logic for parsing and status handling. - Update Unit Tests (tests/tools/http/): Modify mocks and stubs to simulate returning raw response objects and adjust assertions. - Update Documentation: Locate and update existing documentation to reflect the changes in the interface. |
| PLAN_002_CENTRALIZE_HTTP_RETRY.md | Updated Plan to Centralize HTTP Retry Logic | - Phase 1: Analysis and Identification in Clients: Search for direct uses of the @retry decorator from tenacity or other retry libraries, identify loops with try-except blocks simulating retry behavior, check HTTP adapter configurations with max_retries outside central classes, analyze any other manual retry logic implementations. - Phase 2: Verification and Standardization of Central Classes (HTTPClient and RequestsManager): Analyze the HTTPClient and RequestsManager classes in fbpyutils_ai/tools/http.py, confirm the current use of tenacity and HTTPAdapter is appropriate, evaluate whether retry parameters are configurable and meet general requirements. - Phase 3: Refactoring Proposal for Clients: Detail how local retry logic will be removed, ensure that existing calls to HTTPClient or RequestsManager methods by clients do not change signatures, ensure that all retry responsibilities are delegated to the central classes. - Phase 4: Impact Analysis and Unit Test Adjustments: Identify all existing unit tests for the modified client files and for the HTTPClient and RequestsManager classes, analyze how removing retry logic from clients and centralizing/standardizing in the HTTP classes may affect these tests, propose adjustments to the tests. - Phase 5: Implementation and Refactoring: Implement proposed improvements from Phase 2 for the HTTPClient and RequestsManager classes, refactor client files identified in Phase 1 to remove local retry logic, ensure that clients use the central classes for all HTTP requests, implement adjustments to unit tests, run unit tests. |
| PLAN_003_UPDATE_FIRECRAWL_V1.md | Plan to Update FireCrawlTool to API v1 (Self-Hosted) and MCP Support | - Initial Requirements: Update the FireCrawlTool class to use v1 of the firecrawl.dev API service made available locally via SELF HOSTING, implement the services scrape, scrape, extract, map, search and auxiliary methods using the v1 API documentation and HTTPClient, flatten the methods, ensure that only arguments supported by the self-hosted mode are used, implement new methods (scrape_formatted, scrape_multiple) in the FireCrawlTool class that replicate the formatting and parallel processing functionality from fbpyutils_ai/servers/mcp_scrape_server.py, ensure responses always return JSON, follow recommendations from VIBE.md, update/create unit tests, update documentation. - Detailed Steps: Refine __init__, implement/verify auxiliary methods, flatten main methods, implement MCP support - scrape_formatted, implement MCP support - scrape_multiple, update final documentation. |
| PLAN_004_REFACTOR_FIRECRAWL_TOOL.md | Refactoring Plan for the `FireCrawlTool` Class | - Code Modification (fbpyutils_ai/tools/scrape.py): Edit fbpyutils_ai/tools/scrape.py, remove complete definitions of the methods scrape, get_crawl_status, cancel_crawl, get_crawl_errors, get_batch_scrape_status, get_batch_scrape_errors, batch_scrape, get_extract_status, extract, map from the FireCrawlTool class, remove complete definitions of utility functions (private methods) _format_metadata_md, _format_links_md, _format_scrape_result_md, scrape_formatted, scrape_multiple, remove the scrape_and_store function, remove unused imports, keep __init__, scrape, and search methods intact. - Documentation Update: Edit DOC.md, review the section for the FireCrawlTool class, remove documentation and usage examples for the removed methods, maintain and refine documentation for the __init__, scrape and search methods, edit README.md, review and remove any direct mentions or usage examples of removed methods, retain general mentions of "scrape" and "search" capabilities if appropriate, keep the specs/ folder and all its files intact. - Unit Test Update: Identify and remove test files, remove test_batch_scrape.py, test_cancel_crawl.py, test_crawl.py, test_extract.py, test_get_batch_scrape_errors.py, test_get_batch_scrape_status.py, test_get_crawl_errors.py, test_get_crawl_status.py, test_get_extract_status.py, test_map.py from tests/tools/scrape/, review existing test files, review tests/tools/scrape/test_scrape.py, tests/tools/scrape/test_search.py, tests/tools/test_tools.py and tests/servers/mcp_scrape_server.py. - Final Verification and Code Coverage: Run all remaining unit tests, review coverage report. |
| PLAN_005_CREATE_UI_MARIMO.md | Execution Plan | - Create app.firecrawl_tool.py Module: Create fbpyutils_ai/ui/marimo/app.firecrawl_tool.py file, copy the basic structure from app.search_tool.py, import the FireCrawlTool class, consider using fbpyutils_ai/ui/marimo/components.py, define Marimo cells to initialize FireCrawlTool, create UI elements for scrape method parameters, create UI elements for search method parameters, implement logic to call scrape method, implement logic to call search method, display results, organize scrape and search sections inside a mo.accordion. - Integration in General Interface (Future): Create app.main.py file to import and display app.llm_tool.py, app.search_tool.py, and app.firecrawl_tool.py modules in a single interface, the general interface will use mo.ui.sidebar component. - Completion of Existing Modules (Upon Request): To be done as requested for app.llm_tool.py and app.search_tool.py. - Project Documentation Update: Update README.md, TODO.md, TOOLS.md, and TREE.md files to include the new FireCrawlTool and its functionality, add information about the Marimo UI structure. - Memory Bank Update: Update memory bank files to reflect project changes. - Repository Commit: Make meaningful commits after completing each major step. |
| PLAN_006_RELEASE_V0.1.1.md | Detailed Plan | - Create Content for the Home Section in Marimo UI: Define Home content, modify fbpyutils_ai/ui/marimo/app.py. - Update Documentation (README.md, TODO.md, TOOLS.md, TREE.md): Update README.md, update TODO.md, update TOOLS.md, update TREE.md. - Update Memory Bank: Review and update memory_bank/activeContext.md and memory_bank/progress.md. - Implement "Generate Text" and "Generate Embeddings" Subsections in Marimo UI: Modify fbpyutils_ai/ui/marimo/app.py, for "Generate Text" create a function get_llm_generate_text_section(), for "Generate Embeddings" create a function get_llm_generate_embeddings_section(), ensure llm_base_model and llm_embed_model are used properly. - Re-update Documentation: Review README.md, TODO.md, TOOLS.md, TREE.md. - Re-update Memory Bank: Review and update memory_bank/activeContext.md and memory_bank/progress.md. |
