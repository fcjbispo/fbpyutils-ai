# fbpyutils_ai/tools/llm/_vision.py
import os
import base64
import requests

from fbpyutils_ai import logging

# Note: This function assumes it will be bound to an instance of OpenAITool
# and will have access to `self.timeout`, `self.generate_text`, etc.

def describe_image(
    self, image: str, prompt: str, max_tokens: int = 300, temperature: float = 0.4
) -> str:
    """
    Describes an image using the vision API endpoint.

    The image can be provided as a local file path, a remote URL, or a base64 encoded string.
    The method prepares the image and calls `generate_text` in vision mode.

    Args:
        self: The instance of OpenAITool.
        image (str): Path, URL, or base64 content of the image.
        prompt (str): Prompt to guide the image description.
        max_tokens (int): Maximum tokens for the description.
        temperature (float): Sampling temperature for the description.

    Returns:
        str: Description generated by the API, or an empty string on error.
    """
    logging.info(f"Describing image: {image}")
    image_base64 = None

    # Check if the image is a local file
    if os.path.exists(image):
        logging.debug(f"Image identified as local file path: {image}")
        try:
            with open(image, "rb") as img_file:
                image_bytes = img_file.read()
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            logging.debug(f"Successfully read and encoded local image file.")
        except Exception as e:
            logging.error(f"Error reading local image file {image}: {e}", exc_info=True)
            return ""
    # Check if the image is a remote URL
    elif image.startswith("http://") or image.startswith("https://"):
        logging.debug(f"Image identified as URL: {image}")
        try:
            # Use the session from the instance for consistency
            response = self.session.get(image, timeout=self.timeout)
            response.raise_for_status() # Raises HTTPError for bad responses
            image_bytes = response.content
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            logging.debug(f"Successfully downloaded and encoded image from URL.")
        except requests.exceptions.RequestException as e:
            logging.error(f"Error downloading the image from {image}: {e}", exc_info=True)
            return ""
    # Assume the content is already in base64
    else:
        logging.debug("Image assumed to be base64 encoded string.")
        # Basic check for base64 validity could be added here if needed
        # For simplicity, we assume it's valid if it's not a path or URL.
        image_base64 = image


    if not image_base64:
         logging.error("Could not obtain base64 representation for the image.")
         return ""

    # Construct the prompt including the base64 encoded image information
    # Avoid logging the full base64 string which can be very large
    full_prompt_template = (
        f"{prompt}\n\n"
        "Below is the image encoded in base64:\n"
        "{image_base64_placeholder}\n\n" # Placeholder used for logging
        "Provide a detailed description of the image."
    )
    logging.debug(f"Constructed vision prompt (base64 image omitted): {full_prompt_template.format(image_base64_placeholder='[BASE64_IMAGE_DATA]')}")

    # Actual prompt sent to the model
    full_prompt_with_image = (
         f"{prompt}\n\n"
         "Below is the image encoded in base64:\n"
         f"{image_base64}\n\n"
         "Provide a detailed description of the image."
     )

    # Use the generate_text method (bound to the instance) in vision mode
    logging.info(f"Calling generate_text in vision mode for image description.")
    description = self.generate_text(
        full_prompt_with_image, max_tokens=max_tokens, temperature=temperature, vision=True
    )

    if description:
        logging.info(f"Successfully generated image description (length: {len(description)}).")
    else:
        logging.warning("Image description generation returned empty.")
    return description
